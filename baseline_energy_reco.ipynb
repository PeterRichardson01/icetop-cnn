{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Reconstruction Using CNN - Zenith Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from csv import writer\n",
    "from tensorflow import keras \n",
    "from keras import layers, models\n",
    "from keras.callbacks import CSVLogger, EarlyStopping\n",
    "from data_tools import load_preprocessed, dataPrep, filterReco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File directory to folder that holds simulation data \n",
    "simPrefix = '/defaultDir/simFiles/'\n",
    "\n",
    "# Sim data to reconstruct (dir produces theta & phi, make sure to transpose)\n",
    "sim = 'energy'\n",
    "\n",
    "# Set the number of epochs the model should run for \n",
    "numepochs = 3\n",
    "\n",
    "# Name for model\n",
    "name = 'test_filter'\n",
    "\n",
    "# Baseline data prep\n",
    "prep = {'q':None, 't':False, 'normed':True, 'reco':'plane', 'cosz':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_filter0\n"
     ]
    }
   ],
   "source": [
    "# Add identifying number to name\n",
    "i = 0\n",
    "# Saves the h5 file of the model in a folder named models \n",
    "while(os.path.exists('models/{}.h5'.format(name+str(i)))): \n",
    "    i += 1\n",
    "name += str(i)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using functional API for multiple inputs\n",
    "\n",
    "# Input layer \n",
    "charge_input = keras.Input(shape=(10,10,2,), name='charge')\n",
    "\n",
    "# Starts off with three convolutional layers, each one has half the neurons of the previous one \n",
    "conv1_layer = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(charge_input)\n",
    "conv2_layer = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(conv1_layer)\n",
    "conv3_layer = layers.Conv2D(16, kernel_size=3, padding='same', activation=\"relu\")(conv2_layer)\n",
    "\n",
    "# Layers are flattened before Zenith information is added \n",
    "flat_layer = layers.Flatten()(conv3_layer)\n",
    "zenith_input = keras.Input(shape=(1,), name='zenith')\n",
    "concat_layer = layers.Concatenate()([flat_layer, zenith_input])\n",
    "\n",
    "# The flattened layers and the Zenith layer run through 3 dense layers\n",
    "dense1_layer = layers.Dense(256, activation='relu')(concat_layer)\n",
    "dense2_layer = layers.Dense(256, activation='relu')(dense1_layer)\n",
    "dense3_layer = layers.Dense(256, activation=\"relu\")(dense2_layer)\n",
    "\n",
    "# This last dense layer is the output of the model\n",
    "output = layers.Dense(1)(dense3_layer)\n",
    "\n",
    "model = models.Model(inputs=[charge_input, zenith_input], outputs=output, name=name)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_filter0\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "charge (InputLayer)             [(None, 10, 10, 2)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 64)   1216        charge[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 32)   18464       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 10, 10, 16)   4624        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1600)         0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zenith (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1601)         0           flatten_1[0][0]                  \n",
      "                                                                 zenith[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          410112      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          65792       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            257         dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 566,257\n",
      "Trainable params: 566,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of events with a NaN: 2.68\n"
     ]
    }
   ],
   "source": [
    "# Load simulation data from files for training\n",
    "x, y = load_preprocessed(simPrefix, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare event data\n",
    "x_i = dataPrep(x, y, **prep)\n",
    "\n",
    "# Filter NaNs from reconstruction data\n",
    "filterReco(prep, y, x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14354/14354 [==============================] - 379s 26ms/step - loss: 0.0902 - mae: 0.1873 - mse: 0.0902 - val_loss: 0.0307 - val_mae: 0.1321 - val_mse: 0.0307\n"
     ]
    }
   ],
   "source": [
    "# Logs metrics into a csv file between epochs\n",
    "csv_logger = CSVLogger('models/{}.csv'.format(name))\n",
    "\n",
    "# Earlystoping stops the model from training when it starts to overfit to the data\n",
    "# The main parameter we change is the patience \n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10, verbose=0, mode=\"auto\", baseline=None, restore_best_weights=False) \n",
    "callbacks = [early_stop, csv_logger]\n",
    "\n",
    "# Training\n",
    "history = model.fit({\"charge\":x_i[0], \"zenith\":x_i[1].reshape(-1,1)}, y=y[sim], epochs=numepochs, validation_split=0.15, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model results as a .npy and .h5 file\n",
    "model.save('models/%s.h5' % name)\n",
    "np.save('models/%s.npy' % name, prep)\n",
    "\n",
    "type(history.history['loss'])\n",
    "# Get the results of the best epoch and write them to a .csv file\n",
    "num_epoch=len(history.history['loss'])\n",
    "val_loss=np.min(history.history['val_loss'])\n",
    "index=history.history['val_loss'].index(val_loss)\n",
    "loss=history.history['loss'][index]\n",
    "new_row=[name, num_epoch, loss, val_loss]\n",
    "with open('models/results.csv', 'a') as f_object:\n",
    "    csv_writer=writer(f_object)\n",
    "    csv_writer.writerow(new_row)\n",
    "f_object.close() "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7fa6917d79ba6874137c2cee546e23d674c97a8f1fc70b0dd72f9db1e0feed7b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
