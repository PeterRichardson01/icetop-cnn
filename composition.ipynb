{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment of Cosmic Ray Composition Estimation using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from warnings import catch_warnings, filterwarnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import get_event_parameters, get_training_assessment_cut, get_cuts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER SETTINGS TO ADJUST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICETOP_CNN_DATA_DIR = os.getenv('ICETOP_CNN_DATA_DIR')\n",
    "\n",
    "# Edit this file path to point to the models folder containing .h5 and .npy files for each model.\n",
    "MODELS_FOLDER_PATH = os.path.join(ICETOP_CNN_DATA_DIR, 'models')\n",
    "\n",
    "# Simdata folder containing the simulation data.\n",
    "SIMDATA_FOLDER_PATH = os.path.join(os.sep, 'data', 'user', 'fmcnally', 'icetop-cnn', 'simdata')\n",
    "\n",
    "# Option to change font size for all labels within this notebook\n",
    "LABEL_PARAMS = {\n",
    "    'fontsize':20\n",
    "}\n",
    "\n",
    "# The keys will be the names of the models you wish to analyze\n",
    "# The values will be the nuclei to assess for each model\n",
    "# An example might be\n",
    "#   'model1': 'phof'\n",
    "# to assess on all nuclei for a model named \"model1\"\n",
    "MODEL_NAMES_AND_NUCLEI = {\n",
    "    'YOUR MODEL NAME HERE': 'YOUR MODEL COMPOSITION STRING HERE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available models\n",
    "\n",
    "# Ensure that models folder has actually been found\n",
    "assert os.path.exists(MODELS_FOLDER_PATH), f'ERROR: Could not find models folder. Path specified: {MODELS_FOLDER_PATH}'\n",
    "\n",
    "model_list = glob(os.path.join(ICETOP_CNN_DATA_DIR, 'reconstructions', 'comp', '*.npy'))      # Get all model .npy files\n",
    "model_list = [os.path.splitext(os.path.basename(m))[0] for m in model_list]                   # Trim parent directories and file extension\n",
    "\n",
    "param_list = glob(os.path.join(MODELS_FOLDER_PATH, '*', '*.json'))                            # Get all parameter .json files\n",
    "param_list = [os.path.splitext(os.path.basename(p))[0] for p in param_list]                   # Trim parent directories and file extension\n",
    "\n",
    "print('Available models:', sorted(set(model_list).intersection(param_list)))                  # Models that have both .npy and .json files\n",
    "print('\\nModels without parameter files:', sorted(set(model_list).difference(param_list)))    # Models that have a .npy file but no .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic intake of parameters from parameter files\n",
    "# Builds a dictionary mapping model names to their corresponding PREP dictionary\n",
    "model_parameters = {}\n",
    "\n",
    "for model_name, assessment_nuclei in MODEL_NAMES_AND_NUCLEI.items():\n",
    "    # Construct the full .npy model path\n",
    "    model_path = os.path.join(MODELS_FOLDER_PATH, model_name, model_name + '.json')\n",
    "\n",
    "    # Ensure that the model is found (no typos)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f'WARNING: Model {model_name} not found at {MODELS_FOLDER_PATH}')\n",
    "        continue\n",
    "\n",
    "    # Load model parameters and save into dictionary along with assessment nuclei\n",
    "    with open(model_path, 'r') as f:\n",
    "        model_parameters[model_name] = json.load(f)\n",
    "    model_parameters[model_name].update({'assessment_nuclei': assessment_nuclei})\n",
    "    \n",
    "    # Print entry\n",
    "    print(model_name, ':', model_parameters[model_name])\n",
    "\n",
    "assert len(model_parameters), 'ERROR: No models selected for analysis!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load detector inputs and event parameters\n",
    "# In its own cell because this can take a while\n",
    "event_parameters = get_event_parameters(SIMDATA_FOLDER_PATH, composition='phof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = {}\n",
    "cuts = {}\n",
    "\n",
    "comp_conversion = {'p':1, 'h':4, 'o':16, 'f':56}\n",
    "\n",
    "# Calculate reconstructed energies. This can take a bit (a few minutes), but should print out info on each model as it works\n",
    "for model_name, model_prep in model_parameters.items():\n",
    "    \n",
    "    # Print model parameters as the different models predict\n",
    "    print(f'Working on {model_name}...\\n{model_prep}\\n')\n",
    "\n",
    "    # Load model prediction\n",
    "    reconstruction = np.load(os.path.join(ICETOP_CNN_DATA_DIR, 'reconstructions', 'comp', model_name + '.npy'))\n",
    "    \n",
    "    # Load data cut\n",
    "    cut = get_training_assessment_cut(event_parameters, 'assessment', model_prep)\n",
    "\n",
    "    # Nuclei cut\n",
    "    nuclei_to_assess = [comp_conversion[nuclei] for nuclei in model_prep['assessment_nuclei']]\n",
    "\n",
    "    reconstruction = reconstruction[np.isin(event_parameters['comp'][cut], nuclei_to_assess)]\n",
    "    cut *= np.isin(event_parameters['comp'], nuclei_to_assess)\n",
    "\n",
    "    # Save data cut\n",
    "    cuts[model_name] = cut\n",
    "    \n",
    "    # Save model prediction\n",
    "    reconstructions[model_name] = np.argmax(reconstruction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_table = { # HACK\n",
    "    'p': {'weight': 1,  'alias': 0, 'name': 'proton', 'color': 'red'},\n",
    "    'h': {'weight': 4,  'alias': 1, 'name': 'helium', 'color': 'orange'},\n",
    "    'o': {'weight': 16, 'alias': 2, 'name': 'oxygen', 'color': 'green'},\n",
    "    'f': {'weight': 56, 'alias': 3, 'name': 'iron',   'color': 'blue'},\n",
    "}\n",
    "\n",
    "cut_names = ['No Cut', 'Quality Cut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Summary Statistics\n",
    "\n",
    "for cut_name in cut_names:\n",
    "    print(cut_name.upper().center(62)) # Max length of a summary statistic in current format\n",
    "    for model_name, reconstructed_composition in reconstructions.items():\n",
    "        model_cut = cuts[model_name]\n",
    "        reco_cut, data_cut = get_cuts(model_cut, event_parameters, cut_name)\n",
    "        print(f'Output for {model_name}:')\n",
    "        for comp in model_parameters[model_name]['assessment_nuclei']:\n",
    "            model_specific_comp = (event_parameters['comp'] == comp_table[comp]['weight'])[data_cut]\n",
    "            num_model_specific_comp = sum(model_specific_comp)\n",
    "            num_correct_guesses = sum((reconstructed_composition[reco_cut] == comp_table[comp]['alias']) & model_specific_comp)\n",
    "            print(f'  Number of correct {comp_table[comp][\"name\"]} guesses: {num_correct_guesses} (Accuracy = {100*num_correct_guesses/num_model_specific_comp:.2f}%)')\n",
    "            for c in model_parameters[model_name]['assessment_nuclei']:\n",
    "                if c == comp or comp_table[c]['alias'] is None:\n",
    "                    continue\n",
    "                num_incorrect_guesses = sum((reconstructed_composition[reco_cut] == comp_table[c]['alias']) & model_specific_comp)\n",
    "                print(f'    Number of {comp_table[comp][\"name\"]}s labeled as {comp_table[c][\"name\"]}: {num_incorrect_guesses} ({100*num_incorrect_guesses/num_model_specific_comp:.2f}%)')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Accuracy as a Function of Energy\n",
    "\n",
    "bin_min, bin_max, inc = 5, 8, 0.1\n",
    "num_bins = int((1/inc)*(bin_max-bin_min))\n",
    "bin_edges = np.linspace(bin_min, bin_max, num_bins+1)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "y_min, y_max = 0, 1\n",
    "marker_size = 640*inc\n",
    "ncols = len(cut_names)\n",
    "\n",
    "for model_name, reconstructed_composition in reconstructions.items():\n",
    "    fig, axs = plt.subplots(figsize=(13*ncols, 8), ncols=ncols)\n",
    "    for i, cut_name in enumerate(cut_names):\n",
    "        ax = axs[i]\n",
    "        reco_cut, data_cut = get_cuts(cuts[model_name], event_parameters, cut_name)\n",
    "        model_specific_energy = event_parameters['energy'][data_cut]\n",
    "        binned_accuracies, bin_counts = [], []\n",
    "        for comp in model_parameters[model_name]['assessment_nuclei']:\n",
    "            model_specific_comp = (event_parameters['comp'] == comp_table[comp]['weight'])[data_cut].astype(int)\n",
    "            binned_model_specific_comp = np.histogram(model_specific_energy, bins=bin_edges, weights=model_specific_comp)[0].astype(int)\n",
    "            correct_guesses = (reconstructed_composition[reco_cut] == comp_table[comp]['alias']) & model_specific_comp\n",
    "            binned_correct_guesses = np.histogram(model_specific_energy, bins=bin_edges, weights=correct_guesses)[0].astype(int)\n",
    "            with catch_warnings(): # No values in a particular bin means doing a 0/0 division\n",
    "                filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in divide')\n",
    "                binned_accuracy = binned_correct_guesses / binned_model_specific_comp\n",
    "            binned_accuracies.append(binned_accuracy)\n",
    "            bin_counts.append(binned_model_specific_comp)\n",
    "            ax.scatter(bin_centers, binned_accuracy, s=marker_size, color=comp_table[comp]['color'])\n",
    "        ax.scatter(bin_centers, np.mean(binned_accuracies, axis=0), s=marker_size, color='black')\n",
    "        ax.hist(np.repeat(bin_edges[:-1], len(model_parameters[model_name]['assessment_nuclei'])).reshape(-1, len(model_parameters[model_name]['assessment_nuclei'])), bins=bin_edges, density=True, weights=np.asarray(bin_counts).transpose(), histtype='barstacked', color=[comp_table[c]['color'] for c in model_parameters[model_name]['assessment_nuclei']], alpha=0.15)\n",
    "        ax.set_title(f'{model_name} ({cut_name})', fontsize=20)\n",
    "        ax.set_xlabel(r'$\\log_{10}(E_{\\mathrm{true}}/\\mathrm{GeV})$', fontsize=20)\n",
    "        ax.set_ylabel('Accuracy', fontsize=20)\n",
    "        ax.set_xlim(bin_min-inc, bin_max+inc)\n",
    "        ax.set_ylim(y_min-inc, y_max+inc)\n",
    "        ax.tick_params(axis='both', direction='in', length=12, width=2, labelsize=16)\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax.spines[axis].set_linewidth(2)\n",
    "    plt.show()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IceTop-CNN",
   "language": "python",
   "name": "icetop-cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
