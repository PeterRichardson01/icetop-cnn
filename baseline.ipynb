{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmic Ray Energy Reconstruction Using Convolutional Neural Network\n",
    "## Utilizing Charge, Time, and Zenith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "from data_tools import data_prep, get_data_cut, load_preprocessed\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import BatchNormalization, Concatenate, Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Baseline data prep ###\n",
    "\n",
    "# Edit these parameters\n",
    "# Too many to list, look in data_prep in data_tools for a better idea of what each does\n",
    "prep = {'clc':True, 'sta5':False, 'q':None, 't':None, 't_shift':True, 't_clip':0, 'normed':True, 'reco':None, 'cosz':False}\n",
    "\n",
    "# Name for model(s)\n",
    "model_name = 'baseline'\n",
    "\n",
    "# Type of model to train\n",
    "model_type = 'bauwens'\n",
    "\n",
    "# Set the number of epochs the model(s) should run for\n",
    "# Actual result may differ due to early stopping\n",
    "num_epochs = 200\n",
    "\n",
    "# Loss metric to use for training\n",
    "# Suggestion to experiment with 'huber_loss'\n",
    "loss_function = 'huber_loss'\n",
    "\n",
    "# Optimizer to user for training\n",
    "# Default lr is .001\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Other loss metrics to analyze while training\n",
    "# Only for user to monitor - have no effect on model training\n",
    "metrics = ['mae','mse']\n",
    "\n",
    "# File directory to folder that holds models\n",
    "model_prefix = os.getcwd()+'/models'\n",
    "\n",
    "# File directory to folder that holds simulation data \n",
    "sim_prefix = os.getcwd()+'/simdata'\n",
    "\n",
    "# Booleans for easier to read conditionals - no need to change this\n",
    "has_reco, has_time = prep['reco'] != None, prep['t'] != False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load simulation data from files for training\n",
    "x, y = load_preprocessed(sim_prefix, comp=['p','f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare simulation data\n",
    "x_i, idx, pre_cut = data_prep(x, y, 'train', **prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get final data cut ###\n",
    "data_cut = get_data_cut(prep['reco'], y, pre_cut)\n",
    "\n",
    "if has_reco:\n",
    "    x_i[0] = x_i[0][data_cut] # q/t\n",
    "    x_i[1] = x_i[1][data_cut] # z\n",
    "else:\n",
    "    x_i = x_i[data_cut] # q/t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures models are not overwritten\n",
    "i = 0\n",
    "while(os.path.exists('%s/%s' % (model_prefix, model_name+str(i)))): i += 1\n",
    "model_name += str(i)\n",
    "\n",
    "# Charge and Time (if included) input layers\n",
    "data_input = Input(shape=(10,10,x_i[0].shape[-1]), name='data')\n",
    "\n",
    "# Zenith input layer\n",
    "if has_reco:\n",
    "    zenith_input = Input(shape=(1), name='zenith')\n",
    "\n",
    "if model_type == 'baseline':\n",
    "    conv1 = Conv2D(64, kernel_size=3, padding='same', activation='relu', data_format='channels_last')(data_input)\n",
    "    conv2 = Conv2D(32, kernel_size=3, padding='same', activation='relu', data_format='channels_last')(conv1)\n",
    "    conv3 = Conv2D(16, kernel_size=3, padding='same', activation='relu', data_format='channels_last')(conv2)\n",
    "    flat = Flatten()(conv3)\n",
    "    # Must concatenate Zenith input to Flat layer\n",
    "    if has_reco:\n",
    "        flat = Concatenate()([flat, zenith_input])\n",
    "    dense1 = Dense(256, activation='relu')(flat)\n",
    "    dense2 = Dense(256, activation='relu')(dense1)\n",
    "    dense3 = Dense(256, activation='relu')(dense2)\n",
    "    output = Dense(1, activation='relu')(dense3)\n",
    "\n",
    "elif model_type == 'bauwens':   \n",
    "    conv1 = BatchNormalization()(Conv2D(64, kernel_size=3, padding='same', activation='relu', data_format='channels_last')(data_input))\n",
    "    conv2 = BatchNormalization()(Conv2D(128, kernel_size=3, padding='same', activation='relu', data_format='channels_last')(conv1))\n",
    "    maxpool1 = MaxPooling2D(pool_size=3, strides=2, padding='same')(conv2)\n",
    "    conv3 = BatchNormalization()(Conv2D(256, kernel_size=3, padding='same', activation='relu', data_format='channels_last')(maxpool1))\n",
    "    conv4 = BatchNormalization()(Conv2D(512, kernel_size=3, padding='same', activation='relu', data_format='channels_last')(conv3))\n",
    "    maxpool2 = MaxPooling2D(pool_size=3, strides=2, padding='same')(conv4)\n",
    "    conv5 = BatchNormalization()(Conv2D(512, kernel_size=3, padding='same', activation='relu', data_format='channels_last')(maxpool2))\n",
    "    maxpool3 = MaxPooling2D(pool_size=3, strides=2, padding='same')(conv5)\n",
    "    flat = Flatten()(maxpool3)\n",
    "    # Must concatenate Zenith input to Flat layer\n",
    "    if has_reco:\n",
    "        flat = Concatenate()([flat, zenith_input])\n",
    "    dense1 = BatchNormalization()(Dense(1024, activation='relu')(flat))\n",
    "    output = Dense(1, activation='relu')(dense1)\n",
    "\n",
    "else:\n",
    "    raise Exception('Unrecognized model type.')\n",
    "\n",
    "inputs = [data_input]\n",
    "fit_inputs = {'data':x_i}\n",
    "if has_reco:\n",
    "    inputs.append(zenith_input)\n",
    "    fit_inputs = {'data':x_i[0], 'zenith':x_i[1].reshape(-1,1)}\n",
    "model = Model(inputs=inputs, outputs=output, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing, Training, and Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss_function, optimizer=optimizer, metrics=metrics)\n",
    "# Print summary of model. Can be commented out or removed if the text is too much.\n",
    "model.summary()\n",
    "\n",
    "# Arguments to play with are factor (best between 0.1 - 0.8), patience, and min_lr\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=10, mode='min', min_lr=0.0001)\n",
    "# Only argument to play with is patience. Recommended to be greater than twice the reduce_lr patience.\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=25, mode='min', restore_best_weights=True)\n",
    "csv_logger = CSVLogger('%s/%s' % (model_prefix, model_name))\n",
    "\n",
    "history = model.fit(fit_inputs, y=y['energy'][data_cut], epochs=num_epochs, validation_split=0.15, callbacks=[early_stop, csv_logger, reduce_lr])\n",
    "\n",
    "model.save('%s/%s.h5' % (model_prefix, model_name))\n",
    "np.save('%s/%s.npy' % (model_prefix, model_name), prep)\n",
    "\n",
    "val_loss = np.min(history.history['val_loss'])\n",
    "index = history.history['val_loss'].index(val_loss)\n",
    "loss = history.history['loss'][index]\n",
    "new_row = [model_name, index, loss, val_loss]\n",
    "with open('models/results.csv', 'a') as f:\n",
    "    writer(f).writerow(new_row)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31925b19b5fe5a511cc521412368d42da4de764f685469458a6425fd9ad7937b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
