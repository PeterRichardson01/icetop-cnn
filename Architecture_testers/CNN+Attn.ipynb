{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Reconstruction Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Attention\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from data_tools import load_preprocessed, dataPrep, nameModel\n",
    "\n",
    "## FIX THIS!\n",
    "simPrefix = 'D:\\icecube\\sim_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name for model\n",
    "key = 'CNN_attn'\n",
    "\n",
    "# Data preparation: no merging of charge (q), no time layers included (t=False), data normalized from 0-1\n",
    "prep = {'q':None, 't':False, 'normed':True} #i dont understand exactly what all of these options are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of events with a NaN: 2.68\n",
      "dict_keys(['comp', 'energy', 'dir', 'plane_dir', 'laputop_dir', 'small_dir'])\n"
     ]
    }
   ],
   "source": [
    "x, y = load_preprocessed(simPrefix, 'train')\n",
    "print(y.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attn_test\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 10, 10, 2)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 10, 10, 2)    0           input_2[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 8, 8, 64)     1216        attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 8, 8, 64)     0           conv2d[0][0]                     \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 6, 6, 32)     18464       attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 6, 6, 32)     0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 16)     4624        attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           2570        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,874\n",
      "Trainable params: 26,874\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, layers, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "inputs = Input(shape=(10,10,2))\n",
    "\n",
    "#o = layers.Attention()([inputs, inputs]) #.1336 loss compared to .1274 -- WORSE ( Model = 1 layer, then pooling, conv)\n",
    "\n",
    "#Loss on Conv-Conv-Conv = 0.0522\n",
    "\n",
    "#print(tf.shape(o))\n",
    "o = layers.Attention()([inputs, inputs]) #.1336 loss compared to .1274\n",
    "o = layers.Conv2D(64, kernel_size=3, activation='relu', input_shape=(10,10,2))(o)\n",
    "#o = MaxPooling2D(pool_size = (2,2), strides = None)(inputs)\n",
    "o = layers.Attention()([o, o]) #.1336 loss compared to .1274\n",
    "o = layers.Conv2D(32, kernel_size=3, activation='relu')(o)\n",
    "#o = MaxPooling2D(pool_size = (2,2), strides = None)(o)\n",
    "o = layers.Attention()([o,o]) #.1336 loss compared to .1274\n",
    "o = layers.Conv2D(16, kernel_size=3, activation='relu')(o)\n",
    "\n",
    "o = layers.Flatten()(o)\n",
    "outputs = layers.Dense(10)(o)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs, name=\"attn_test\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = y['energy']\n",
    "comp = y['comp']\n",
    "theta, phi = y['dir'].transpose()\n",
    "nevents = len(energy)\n",
    "trainCut = (np.random.uniform(size=nevents) < 0.85)\n",
    "testCut = np.logical_not(trainCut)\n",
    "\n",
    "# Establish arrays to be trained on\n",
    "x_i = dataPrep(x, y, **prep)\n",
    "temp_y = energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "14592/14592 [==============================] - 102s 7ms/step - loss: 0.2055 - mse: 0.2055 - val_loss: 0.1029 - val_mse: 0.1029\n",
      "Epoch 2/3\n",
      "14592/14592 [==============================] - 101s 7ms/step - loss: 0.0980 - mse: 0.0980 - val_loss: 0.1299 - val_mse: 0.1299\n",
      "Epoch 3/3\n",
      "14592/14592 [==============================] - 100s 7ms/step - loss: 0.0890 - mse: 0.0890 - val_loss: 0.1174 - val_mse: 0.1174\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_i[trainCut], temp_y[trainCut], validation_data=(x_i[testCut], temp_y[testCut]), epochs=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to file for easy loading\n",
    "## WHERE ARE YOU SAVING TO?\n",
    "model.save('model_%s.h5' % key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
