{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Reconstruction Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Attention\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from data_tools import load_preprocessed, dataPrep, nameModel\n",
    "\n",
    "## FIX THIS!\n",
    "simPrefix = 'D:\\icecube\\sim_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name for model\n",
    "key = 'Conv_Product'\n",
    "\n",
    "# Data preparation: no merging of charge (q), no time layers included (t=False), data normalized from 0-1\n",
    "prep = {'q':'product', 't':False, 'normed':False, }#cosz = True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of events with a NaN: 2.68\n",
      "dict_keys(['comp', 'energy', 'dir', 'plane_dir', 'laputop_dir', 'small_dir'])\n"
     ]
    }
   ],
   "source": [
    "x, y = load_preprocessed(simPrefix, 'train')\n",
    "print(y.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_1480/1366296848.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\CADENH~1\\AppData\\Local\\Temp/ipykernel_1480/1366296848.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    o = layers.Conv2D(64, kernel_size=3, activation='relu', input_shape=(10,10,1))(inputs)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "def model_builder(hp):\n",
    "\n",
    "    \n",
    "o = layers.Conv2D(64, kernel_size=3, activation='relu', input_shape=(10,10,1))(inputs)\n",
    "#o = layers.LayerNormalization(axis=1)(o)\n",
    "o = layers.Conv2D(32, kernel_size=3, activation='relu')(o)\n",
    "#o = layers.LayerNormalization(axis=1)(o)\n",
    "o = layers.Conv2D(16, kernel_size=3, activation='relu')(o)\n",
    "#o = layers.LayerNormalization(axis=1)(o)\n",
    "o = Flatten()(o)\n",
    "outputs = Dense(2)(o)\n",
    "#outputs = layers.GlobalAveragePooling2D()(o)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs, name=\"attn_test\")\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attn_test\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 10, 10, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 64)          32        \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 32)          18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 32)          24        \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 16)          16        \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 24,314\n",
      "Trainable params: 24,278\n",
      "Non-trainable params: 36\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, layers, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "inputs = Input(shape=(10,10,1))\n",
    "\n",
    "o = layers.Conv2D(64, kernel_size=3, activation='relu', input_shape=(10,10,1))(inputs)\n",
    "o = layers.BatchNormalization(axis=1)(o)\n",
    "o = layers.Conv2D(32, kernel_size=3, activation='relu')(o)\n",
    "o = layers.BatchNormalization(axis=1)(o)\n",
    "o = layers.Conv2D(16, kernel_size=3, activation='relu')(o)\n",
    "o = layers.BatchNormalization(axis=1)(o)\n",
    "o = Flatten()(o)\n",
    "outputs = Dense(2)(o)\n",
    "#outputs = layers.GlobalAveragePooling2D()(o)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs, name=\"attn_test\")\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = y['energy']\n",
    "comp = y['comp']\n",
    "theta, phi = y['dir'].transpose()\n",
    "nevents = len(energy)\n",
    "trainCut = (np.random.uniform(size=nevents) < 0.85)\n",
    "testCut = np.logical_not(trainCut)\n",
    "\n",
    "# Establish arrays to be trained on\n",
    "x_i = dataPrep(x, y, **prep)\n",
    "\n",
    "\n",
    "\n",
    "temp_y = energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "468/468 [==============================] - 96s 205ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 2/3\n",
      "468/468 [==============================] - 94s 200ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 3/3\n",
      "468/468 [==============================] - 96s 204ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0394 - val_mse: 0.0394\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_i[trainCut], temp_y[trainCut], validation_data=(x_i[testCut], temp_y[testCut]), epochs=3, batch_size = 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to file for easy loading\n",
    "## WHERE ARE YOU SAVING TO?\n",
    "model.save('model_%s.h5' % key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    #print(model.get_layer(index = i).get_weights())\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comp': array([ 1,  1,  1, ..., 56, 56, 56], dtype=int64), 'energy': array([5.13847214, 5.13847214, 5.34288138, ..., 6.91190239, 6.91190239,\n",
      "       6.91190239]), 'dir': array([[2.92503931, 3.90685368],\n",
      "       [2.92503931, 3.90685368],\n",
      "       [2.7859734 , 4.8815546 ],\n",
      "       ...,\n",
      "       [2.17614535, 3.62439525],\n",
      "       [2.17614535, 3.62439525],\n",
      "       [2.17614535, 3.62439525]]), 'plane_dir': array([[2.888150384237141, 4.041238923755302],\n",
      "       [2.9104651693856254, 3.8575433691584395],\n",
      "       [2.7652575606033416, 4.843763269685228],\n",
      "       ...,\n",
      "       [2.1967368639002016, 3.5506960777999406],\n",
      "       [2.2040490115868696, 3.5975026573490676],\n",
      "       [2.1792771408108615, 3.6343438039541875]], dtype=object), 'laputop_dir': array([[None, None],\n",
      "       [None, None],\n",
      "       [None, None],\n",
      "       ...,\n",
      "       [2.169848069946557, 3.6150110129485924],\n",
      "       [None, None],\n",
      "       [2.193166465600582, 3.6230477763857687]], dtype=object), 'small_dir': array([[2.888150384237141, 4.041238923755302],\n",
      "       [2.9104651693856254, 3.8575433691584395],\n",
      "       [2.7652575606033416, 4.843763269685228],\n",
      "       ...,\n",
      "       [2.169848069946557, 3.6150110129485924],\n",
      "       [2.2040490115868696, 3.5975026573490676],\n",
      "       [2.193166465600582, 3.6230477763857687]], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
