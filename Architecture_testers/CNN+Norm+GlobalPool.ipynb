{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Reconstruction Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Attention\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from data_tools import load_preprocessed, dataPrep, nameModel\n",
    "\n",
    "## FIX THIS!\n",
    "simPrefix = 'D:\\icecube\\sim_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1503934710012946153\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name for model\n",
    "key = 'Best_w_zenith_nocos'\n",
    "\n",
    "# Data preparation: no merging of charge (q), no time layers included (t=False), data normalized from 0-1\n",
    "prep = {'q':'product', 't':False, 'normed':False, 'reco' : 'plane' , 'cosz' : False}#cosz = True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of events with a NaN: 2.68\n",
      "dict_keys(['comp', 'energy', 'dir', 'plane_dir', 'laputop_dir', 'small_dir'])\n"
     ]
    }
   ],
   "source": [
    "x, y = load_preprocessed(simPrefix, 'train') #filter nans out before training!\n",
    "print(y.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attn_test\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 10, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 8, 8, 64)     640         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 8, 8, 64)     0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 8, 8, 64)    32          ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 6, 6, 32)     18464       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 6, 6, 32)     0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 6, 6, 32)    24          ['dropout_1[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 4, 4, 16)     4624        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 4, 16)     0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 4, 4, 16)    16          ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 256)          0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 257)          0           ['flatten[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            258         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,058\n",
      "Trainable params: 24,022\n",
      "Non-trainable params: 36\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, layers, Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Concatenate, Dropout\n",
    "\n",
    "\n",
    "inputs = Input(shape=(10,10,1))\n",
    "zen_input = Input(shape = (1,))\n",
    "\n",
    "o = layers.Conv2D(64, kernel_size=3, activation='relu', input_shape=(10,10,1))(inputs)\n",
    "o = layers.Dropout(.85)(o)\n",
    "o = layers.BatchNormalization(axis=1)(o)\n",
    "o = layers.Conv2D(32, kernel_size=3, activation='relu')(o)\n",
    "o = layers.Dropout(.85)(o)\n",
    "o = layers.BatchNormalization(axis=1)(o)\n",
    "o = layers.Conv2D(16, kernel_size=3, activation='relu')(o)\n",
    "o = layers.Dropout(.85)(o)\n",
    "o = layers.BatchNormalization(axis=1)(o)\n",
    "o = Flatten()(o)\n",
    "o = Concatenate()([o,zen_input])\n",
    "#o = Dense(100,activation='relu')(o)\n",
    "#o = layers.LayerNormalization(axis=1)(o)\n",
    "#o = layers.Dropout(.7)(o)\n",
    "#o = Dense(100, activation='relu')(o)\n",
    "#o = layers.LayerNormalization(axis=1)(o)\n",
    "#o = layers.Dropout(.6)(o)\n",
    "outputs = Dense(1, activation='relu')(o)\n",
    "#outputs = layers.GlobalAveragePooling2D()(o)\n",
    "#outputs = layers.GlobalAveragePooling2D()(o)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[inputs, zen_input], outputs= outputs ,name=\"attn_test\")\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='SGD', metrics=['mse'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = y['energy']\n",
    "comp = y['comp']\n",
    "theta, phi = y['dir'].transpose()\n",
    "nevents = len(energy)\n",
    "trainCut = (np.random.uniform(size=nevents) < 0.85)\n",
    "testCut = np.logical_not(trainCut)\n",
    "\n",
    "# Establish arrays to be trained on\n",
    "x_i = dataPrep(x, y, **prep)\n",
    "\n",
    "\n",
    "\n",
    "e_y = energy\n",
    "comp_y = y['comp']\n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "zendata = x_i[1]\n",
    "zenpd = pd.DataFrame(zendata)\n",
    "zenpd.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7177/7177 [==============================] - 157s 22ms/step - loss: 0.5350 - mse: 0.5350 - val_loss: 0.5960 - val_mse: 0.5960\n",
      "Epoch 2/5\n",
      "7177/7177 [==============================] - 149s 21ms/step - loss: 0.4681 - mse: 0.4681 - val_loss: 0.4116 - val_mse: 0.4116\n",
      "Epoch 3/5\n",
      "7177/7177 [==============================] - 147s 21ms/step - loss: 0.4597 - mse: 0.4597 - val_loss: 0.3799 - val_mse: 0.3799\n",
      "Epoch 4/5\n",
      "7177/7177 [==============================] - 154s 22ms/step - loss: 0.4554 - mse: 0.4554 - val_loss: 0.3852 - val_mse: 0.3852\n",
      "Epoch 5/5\n",
      "7177/7177 [==============================] - 151s 21ms/step - loss: 0.4531 - mse: 0.4531 - val_loss: 0.3886 - val_mse: 0.3886\n"
     ]
    }
   ],
   "source": [
    "#look into talos for hyperparameter tuning w multiple inputs\n",
    "\n",
    "history = model.fit([x_i[0], x_i[1]] ,e_y, validation_split = .15, epochs=5, batch_size = 64)\n",
    "\n",
    "#4.28 is the one to beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to file for easy loading\n",
    "## WHERE ARE YOU SAVING TO?\n",
    "model.save('smallmodel_%s.h5' % key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.5350443720817566, 0.46808868646621704, 0.45971113443374634, 0.45543572306632996, 0.4530792236328125], 'mse': [0.5350443720817566, 0.46808868646621704, 0.45971113443374634, 0.45543572306632996, 0.4530792236328125], 'val_loss': [0.595996081829071, 0.4116112291812897, 0.37990546226501465, 0.3851621747016907, 0.3885958194732666], 'val_mse': [0.595996081829071, 0.4116112291812897, 0.37990546226501465, 0.3851621747016907, 0.3885958194732666]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.5350443720817566, 0.46808868646621704, 0.45971113443374634, 0.45543572306632996, 0.4530792236328125], 'mse': [0.5350443720817566, 0.46808868646621704, 0.45971113443374634, 0.45543572306632996, 0.4530792236328125], 'val_loss': [0.595996081829071, 0.4116112291812897, 0.37990546226501465, 0.3851621747016907, 0.3885958194732666], 'val_mse': [0.595996081829071, 0.4116112291812897, 0.37990546226501465, 0.3851621747016907, 0.3885958194732666]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "print(history.history)\n",
    "f = open('smallmodel_%s.np' % key, 'wb')\n",
    "np.save(f, prep)\n",
    "j =json.dumps(prep) \n",
    "f2 = open('smallmodel_%s.json' % key, 'w')\n",
    "f2.write(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_23836/1366296848.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\CADENH~1\\AppData\\Local\\Temp/ipykernel_23836/1366296848.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    o = layers.Conv2D(64, kernel_size=3, activation='relu', input_shape=(10,10,1))(inputs)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "def model_builder(hp):\n",
    "\n",
    "    \n",
    "o = layers.Conv2D(64, kernel_size=3, activation='relu', input_shape=(10,10,1))(inputs)\n",
    "#o = layers.LayerNormalization(axis=1)(o)\n",
    "o = layers.Conv2D(32, kernel_size=3, activation='relu')(o)\n",
    "#o = layers.LayerNormalization(axis=1)(o)\n",
    "o = layers.Conv2D(16, kernel_size=3, activation='relu')(o)\n",
    "#o = layers.LayerNormalization(axis=1)(o)\n",
    "o = Flatten()(o)\n",
    "outputs = Dense(2)(o)\n",
    "#outputs = layers.GlobalAveragePooling2D()(o)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs, name=\"attn_test\")\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< Updated upstream
   "version": "3.9.7"
=======
   "version": "3.9.8"
>>>>>>> Stashed changes
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
