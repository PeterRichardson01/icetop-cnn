{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Reconstruction Using CNN - Both Charges and Cos(Zenith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import callbacks\n",
    "\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from data_tools import load_preprocessed, dataPrep, nameModel\n",
    "\n",
    "simPrefix = os.getcwd()+'\\\\simdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of events with a NaN: 2.68\n"
     ]
    }
   ],
   "source": [
    "x, y = load_preprocessed(simPrefix, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549773, 10, 10, 4)\n",
      "dict_keys(['comp', 'energy', 'dir', 'plane_dir', 'laputop_dir', 'small_dir'])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.keys())\n",
    "# each station has 2 tanks, each tank has 2 DOMs (high/log gain)\n",
    "# each tank measures charge and time\n",
    "# each station gives 2 charges and 2 times, 4 total pieces of data per station\n",
    "# stations arranged in 10x10 square lattice, 2 corners of square unused\n",
    "# charge measured in VEM, vertical equivalent muon\n",
    "\n",
    "# 'dir' is true direction, rest of dir are reconstruted by simulations\n",
    "# 'plane_dir' assumes shower is flat plane\n",
    "# 'laputop_dir' performs likelihood analysis\n",
    "# 'small_dir' compromises between plane and laputop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Model\n",
    "- Input: no charge merge, no time layers included, normalized data, combined with cosine of zenith angle\n",
    "- Layers: Two convolutional layers for charge, then combined with zenith\n",
    "- Output: Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name for model\n",
    "key = 'q1q2cosZ'\n",
    "i = 0\n",
    "while(os.path.exists('models/model_{}.h5'.format(key+str(i)))):\n",
    "    i = i + 1\n",
    "key = key+str(i)\n",
    "numepochs = 20\n",
    "# Data preparation: no merging of charge (q), no time layers included (t=False), data normalized from 0-1\n",
    "prep = {'q':None, 't':False, 'normed':True, 'reco':'plane', 'cosz':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using functional API for multiple inputs\n",
    "charge_input=keras.Input(shape=(10,10,2,))\n",
    "\n",
    "conv1_layer = layers.Conv2D(64,kernel_size=3,padding='same',activation='relu')(charge_input)\n",
    "batch1_layer = layers.BatchNormalization()(conv1_layer) # default -> axis = -1, \n",
    "drop1_layer = layers.Dropout(0.2)(batch1_layer)\n",
    "\n",
    "conv2_layer = layers.Conv2D(32,kernel_size=3,padding='same',activation='relu')(conv1_layer)\n",
    "batch2_layer = layers.BatchNormalization()(conv2_layer)\n",
    "drop2_layer = layers.Dropout(0.2)(batch2_layer)\n",
    "\n",
    "conv3_layer = layers.Conv2D(16, kernel_size=3, padding='same',activation=\"relu\")(conv2_layer)\n",
    "\n",
    "flat_layer = layers.Flatten()(conv3_layer)\n",
    "zenith_input=keras.Input(shape=(1,))\n",
    "concat_layer = layers.Concatenate()([flat_layer,zenith_input])\n",
    "#output = layers.Dense(1)(concat_layer)\n",
    "\n",
    "dense1_layer = layers.Dense(512,activation='relu')(concat_layer)\n",
    "batch3_layer = layers.BatchNormalization()(dense1_layer)\n",
    "drop3_layer = layers.Dropout(0.2)(batch3_layer)\n",
    "\n",
    "dense2_layer = layers.Dense(512,activation='relu')(dense1_layer)\n",
    "batch4_layer = layers.BatchNormalization()(dense2_layer)\n",
    "drop4_layer = layers.Dropout(0.2)(batch4_layer)\n",
    "\n",
    "dense3_layer = layers.Dense(512,activation=\"relu\")(dense2_layer)\n",
    "\n",
    "output = layers.Dense(1)(dense3_layer)\n",
    "\n",
    "model = models.Model(inputs=[charge_input,zenith_input],outputs=output,name=key)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','mse'])\n",
    "\n",
    "## Old model used for reference\n",
    "#model = Sequential(name=nameModel(prep, 'test'))  # Automatic naming for flexible assessment later\n",
    "## Add model layers\n",
    "#model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(10,10,2)))\n",
    "#model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(1)) # No activation function for last layer of regression model\n",
    "\n",
    "## Compile model\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish arrays to be trained on\n",
    "x_i = dataPrep(x, y, **prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 85/15 split for training/validation\n",
    "energy = x_i[2]['energy']\n",
    "comp = x_i[2]['comp']\n",
    "theta, phi = x_i[2]['dir'].transpose()\n",
    "nevents = len(energy)\n",
    "trainCut = (np.random.uniform(size=nevents) < 0.85)\n",
    "testCut = np.logical_not(trainCut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540381,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540381,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"q1q2cosZ3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10, 10, 2)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 10, 10, 64)   1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 10, 10, 32)   18464       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 10, 10, 16)   4624        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1600)         0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1601)         0           flatten[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          820224      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            513         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,370,353\n",
      "Trainable params: 1,370,353\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model,\"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14354/14354 [==============================] - 270s 19ms/step - loss: 0.0820 - mae: 0.1820 - mse: 0.0820 - val_loss: 0.0278 - val_mae: 0.1268 - val_mse: 0.0278\n",
      "Epoch 2/20\n",
      "14354/14354 [==============================] - 271s 19ms/step - loss: 0.0307 - mae: 0.1312 - mse: 0.0307 - val_loss: 0.0278 - val_mae: 0.1241 - val_mse: 0.0278\n",
      "Epoch 3/20\n",
      "14354/14354 [==============================] - 271s 19ms/step - loss: 0.0280 - mae: 0.1244 - mse: 0.0280 - val_loss: 0.0266 - val_mae: 0.1224 - val_mse: 0.0266\n",
      "Epoch 4/20\n",
      "14354/14354 [==============================] - 273s 19ms/step - loss: 0.0268 - mae: 0.1213 - mse: 0.0268 - val_loss: 0.0256 - val_mae: 0.1154 - val_mse: 0.0256\n",
      "Epoch 5/20\n",
      "14354/14354 [==============================] - 270s 19ms/step - loss: 0.0259 - mae: 0.1189 - mse: 0.0259 - val_loss: 0.0201 - val_mae: 0.1018 - val_mse: 0.0201\n",
      "Epoch 6/20\n",
      "14354/14354 [==============================] - 265s 18ms/step - loss: 0.0253 - mae: 0.1172 - mse: 0.0253 - val_loss: 0.0223 - val_mae: 0.1087 - val_mse: 0.0223\n",
      "Epoch 7/20\n",
      "14354/14354 [==============================] - 263s 18ms/step - loss: 0.0248 - mae: 0.1160 - mse: 0.0248 - val_loss: 0.0240 - val_mae: 0.1150 - val_mse: 0.0240\n",
      "Epoch 8/20\n",
      "14354/14354 [==============================] - 264s 18ms/step - loss: 0.0244 - mae: 0.1149 - mse: 0.0244 - val_loss: 0.0203 - val_mae: 0.1027 - val_mse: 0.0203\n",
      "Epoch 9/20\n",
      "14354/14354 [==============================] - 263s 18ms/step - loss: 0.0241 - mae: 0.1139 - mse: 0.0241 - val_loss: 0.0219 - val_mae: 0.1059 - val_mse: 0.0219\n",
      "Epoch 10/20\n",
      "14354/14354 [==============================] - 263s 18ms/step - loss: 0.0237 - mae: 0.1128 - mse: 0.0237 - val_loss: 0.0196 - val_mae: 0.1013 - val_mse: 0.0196\n",
      "Epoch 11/20\n",
      "14354/14354 [==============================] - 264s 18ms/step - loss: 0.0236 - mae: 0.1127 - mse: 0.0236 - val_loss: 0.0210 - val_mae: 0.1065 - val_mse: 0.0210\n",
      "Epoch 12/20\n",
      "14354/14354 [==============================] - 264s 18ms/step - loss: 0.0234 - mae: 0.1122 - mse: 0.0234 - val_loss: 0.0225 - val_mae: 0.1075 - val_mse: 0.0225\n",
      "Epoch 13/20\n",
      "14354/14354 [==============================] - 264s 18ms/step - loss: 0.0232 - mae: 0.1119 - mse: 0.0232 - val_loss: 0.0210 - val_mae: 0.1059 - val_mse: 0.0210\n",
      "Epoch 14/20\n",
      "14354/14354 [==============================] - 268s 19ms/step - loss: 0.0230 - mae: 0.1113 - mse: 0.0230 - val_loss: 0.0223 - val_mae: 0.1089 - val_mse: 0.0223\n",
      "Epoch 15/20\n",
      "14354/14354 [==============================] - 273s 19ms/step - loss: 0.0229 - mae: 0.1110 - mse: 0.0229 - val_loss: 0.0207 - val_mae: 0.1048 - val_mse: 0.0207\n",
      "Epoch 16/20\n",
      "14354/14354 [==============================] - 272s 19ms/step - loss: 0.0228 - mae: 0.1107 - mse: 0.0228 - val_loss: 0.0261 - val_mae: 0.1151 - val_mse: 0.0261\n",
      "Epoch 17/20\n",
      "14354/14354 [==============================] - 273s 19ms/step - loss: 0.0227 - mae: 0.1104 - mse: 0.0227 - val_loss: 0.0213 - val_mae: 0.1057 - val_mse: 0.0213\n",
      "Epoch 18/20\n",
      "14354/14354 [==============================] - 264s 18ms/step - loss: 0.0226 - mae: 0.1104 - mse: 0.0226 - val_loss: 0.0241 - val_mae: 0.1149 - val_mse: 0.0241\n",
      "Epoch 19/20\n",
      "14354/14354 [==============================] - 264s 18ms/step - loss: 0.0225 - mae: 0.1100 - mse: 0.0225 - val_loss: 0.0226 - val_mae: 0.1078 - val_mse: 0.0226\n",
      "Epoch 20/20\n",
      "14354/14354 [==============================] - 264s 18ms/step - loss: 0.0225 - mae: 0.1098 - mse: 0.0225 - val_loss: 0.0207 - val_mae: 0.1060 - val_mse: 0.0207\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "csv_logger = callbacks.CSVLogger('models/{}'.format(key))\n",
    "early_stop = callbacks.EarlyStopping(patience=10, restore_best_weights=True) # default -> val_loss\n",
    "checkpoint = callbacks.ModelCheckpoint('models/model_%s.h5' % key,save_best_only=True)\n",
    "callbacklist = [early_stop, csv_logger,checkpoint]\n",
    "history = model.fit(\n",
    "    x=[x_i[0],x_i[1]], y=energy, epochs=numepochs,validation_split=0.15,callbacks=callbacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to file for easy loading\n",
    "## WHERE ARE YOU SAVING TO?\n",
    "np.save('models/model_%s.npy' % key,prep)\n",
    "model.save('models/model_%s.h5' % key)\n",
    "f = open(\"results.txt\", \"a\")\n",
    "now = datetime.now()\n",
    "f.write(\"{}\\t{}\\tepochs:{}\\tloss:{},{}\\n\".format(\n",
    "    now.strftime(\"%m/%d/%Y %H:%M:%S\"),\n",
    "    key,\n",
    "    len(history.history['loss']),\n",
    "    history.history['loss'][len(history.history['loss'])-1],\n",
    "    history.history['val_loss'][len(history.history['loss'])-1]\n",
    "))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
