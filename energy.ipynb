{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment of Cosmic Ray Energy Estimation using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import get_event_parameters, get_training_assessment_cut, get_cuts, r_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER SETTINGS TO ADJUST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this file path to point to the models folder containing .h5 and .npy files for each model.\n",
    "ICETOP_CNN_DATA_DIR = os.getenv['ICETOP_CNN_DATA_DIR']\n",
    "MODELS_FOLDER_PATH = os.path.join(ICETOP_CNN_DATA_DIR, 'models')\n",
    "\n",
    "# Edit this file path to point to the simdata folder containing the simulation data.\n",
    "SIMDATA_FOLDER_PATH = os.path.join(ICETOP_CNN_DATA_DIR, 'simdata')\n",
    "\n",
    "# Option to change font size for all labels within this notebook\n",
    "LABEL_PARAMS = {\n",
    "    'fontsize':20\n",
    "}\n",
    "\n",
    "# The keys will be the names of the models you wish to analyze\n",
    "# The values will be the nuclei to assess for each model\n",
    "MODEL_NAMES_AND_NUCLEI = {\n",
    "    '[YOUR MODEL NAME HERE]': '[YOUR MODEL COMPOSITION STRING HERE]'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available models\n",
    "\n",
    "# Ensure that models folder has actually been found\n",
    "assert os.path.exists(MODELS_FOLDER_PATH), f'ERROR: Could not find models folder. Path specified: {MODELS_FOLDER_PATH}'\n",
    "\n",
    "model_list = glob(os.path.join(ICETOP_CNN_DATA_DIR, 'reconstructions', 'energy', '*.npy'))                     # Get all model .npy files\n",
    "model_list = [os.path.splitext(os.path.basename(m))[0] for m in model_list]     # Trim parent directories and file extension\n",
    "\n",
    "param_list = glob(os.path.join(MODELS_FOLDER_PATH, '*', '*.json'))                   # Get all parameter .json files\n",
    "param_list = [os.path.splitext(os.path.basename(p))[0] for p in param_list]     # Trim parent directories and file extension\n",
    "\n",
    "print('Available models:', sorted(set(model_list).intersection(param_list)))                  # Models that have both .npy and .json files\n",
    "print('\\nModels without parameter files:', sorted(set(model_list).difference(param_list)))    # Models that have a .npy file but no .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic intake of parameters from parameter files\n",
    "# Builds a dictionary mapping model names to their corresponding PREP dictionary\n",
    "model_parameters = {}\n",
    "\n",
    "for model_name, assessment_nuclei in MODEL_NAMES_AND_NUCLEI.items():\n",
    "    # Construct the full .npy model path\n",
    "    model_path = os.path.join(MODELS_FOLDER_PATH, model_name, model_name + '.json')\n",
    "\n",
    "    # Ensure that the model is found (no typos)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f'WARNING: Model {model_name} not found at {MODELS_FOLDER_PATH}')\n",
    "        continue\n",
    "\n",
    "    # Load model parameters and save into dictionary along with assessment nuclei\n",
    "    with open(model_path, 'r') as f:\n",
    "        model_parameters[model_name] = json.load(f)\n",
    "    model_parameters[model_name].update({'assessment_nuclei': assessment_nuclei})\n",
    "    \n",
    "    # Print entry\n",
    "    print(model_name, ':', model_parameters[model_name])\n",
    "\n",
    "assert len(model_parameters), 'ERROR: No models selected for analysis!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load detector inputs and event parameters\n",
    "# In its own cell because this can take a while\n",
    "event_parameters = get_event_parameters(SIMDATA_FOLDER_PATH, composition='phof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = {}\n",
    "cuts = {}\n",
    "\n",
    "comp_conversion = {'p':1, 'h':4, 'o':16, 'f':56}\n",
    "\n",
    "# Calculate reconstructed energies. This can take a bit (a few minutes), but should print out info on each model as it works\n",
    "for model_name, model_prep in model_parameters.items():\n",
    "    \n",
    "    # Print model parameters as the different models predict\n",
    "    print(f'Working on {model_name}...\\n{model_prep}\\n')\n",
    "\n",
    "    # Load model prediction\n",
    "    reconstruction = np.load(os.path.join(ICETOP_CNN_DATA_DIR, 'reconstructions', 'energy', model_name + '.npy')).flatten()\n",
    "    \n",
    "    # Load data cut\n",
    "    cut = get_training_assessment_cut(event_parameters, 'assessment', model_prep)\n",
    "\n",
    "    # Nuclei cut\n",
    "    nuclei_to_assess = [comp_conversion[nuclei] for nuclei in model_prep['assessment_nuclei']]\n",
    "\n",
    "    reconstruction = reconstruction[np.isin(event_parameters['comp'][cut], nuclei_to_assess)]\n",
    "    cut *= np.isin(event_parameters['comp'], nuclei_to_assess)\n",
    "\n",
    "    # Save data cut\n",
    "    cuts[model_name] = cut\n",
    "    \n",
    "    # Save model prediction\n",
    "    reconstructions[model_name] = reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, reconstructed_energy in reconstructions.items():\n",
    "    log_difference = .1\n",
    "    diffs = reconstructed_energy - event_parameters['energy'][cuts[model_name]]\n",
    "    uncontained_diffs = reconstructed_energy[event_parameters['uncontained_cut'][cuts[model_name]]] - event_parameters['energy'][cuts[model_name] * event_parameters['uncontained_cut']]\n",
    "    quality_diffs = reconstructed_energy[event_parameters['quality_cut'][cuts[model_name]]] - event_parameters['energy'][cuts[model_name] * event_parameters['quality_cut']]\n",
    "    print(f'PERCENTAGE OF EVENTS RECONSTRUCTED WITHIN {log_difference} ORDER OF MAGNITUDE')\n",
    "    print(f'Unfiltered events  | {(100 * len(list(filter(lambda x: abs(x) <= log_difference, diffs))) / len(diffs)):.2f}%')\n",
    "    print(f'Uncontained events | {(100 * len(list(filter(lambda x: abs(x) <= log_difference, uncontained_diffs))) / len(uncontained_diffs)):.2f}%')\n",
    "    print(f'Quality-cut events | {(100 * len(list(filter(lambda x: abs(x) <= log_difference, quality_diffs))) / len(quality_diffs)):.2f}%')\n",
    "\n",
    "    reco_percent = 15\n",
    "    percent_diffs = 100 * (r_log(reconstructed_energy) - r_log(event_parameters['energy'][cuts[model_name]])) / r_log(event_parameters['energy'][cuts[model_name]])\n",
    "    uncontained_percent_diffs = 100 * (r_log(reconstructed_energy[event_parameters['uncontained_cut'][cuts[model_name]]]) - r_log(event_parameters['energy'][cuts[model_name] * event_parameters['uncontained_cut']])) / r_log(event_parameters['energy'][cuts[model_name] * event_parameters['uncontained_cut']])\n",
    "    quality_percent_diffs = 100 * (r_log(reconstructed_energy[event_parameters['quality_cut'][cuts[model_name]]]) - r_log(event_parameters['energy'][cuts[model_name] * event_parameters['quality_cut']])) / r_log(event_parameters['energy'][cuts[model_name] * event_parameters['quality_cut']])\n",
    "    print(f'PERCENTAGE OF EVENTS RECONSTRUCTED WITHIN {reco_percent}% OF THEIR TRUE ENERGIES')\n",
    "    print(f'Unfiltered events  | {(100 * len(list(filter(lambda x: abs(x) <= reco_percent, percent_diffs))) / len(percent_diffs)):.2f}%')\n",
    "    print(f'Uncontained events | {(100 * len(list(filter(lambda x: abs(x) <= reco_percent, uncontained_percent_diffs))) / len(uncontained_percent_diffs)):.2f}%')\n",
    "    print(f'Quality-cut events | {(100 * len(list(filter(lambda x: abs(x) <= reco_percent, quality_percent_diffs))) / len(quality_percent_diffs)):.2f}%')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebins = np.linspace(5, 8, 181)\n",
    "evalues = (ebins[:-1] + ebins[1:]) / 2\n",
    "\n",
    "cut_names = ['No Cut', 'Quality Cut']\n",
    "ncols, nrows = len(cut_names), len(MODEL_NAMES_AND_NUCLEI.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Energy Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot logged energy resolution\n",
    "\n",
    "hist_args = {'range':(-2,2), 'bins':121, 'density': True, 'histtype':'step', 'log':True, 'linewidth':4}\n",
    "fig, axs = plt.subplots(figsize=(13*ncols, 8), ncols=ncols)\n",
    "\n",
    "for i, cut_name in enumerate(cut_names):\n",
    "    for model_name, model_description in MODEL_NAMES_AND_NUCLEI.items():\n",
    "        reconstructions_cut, energy_cut = get_cuts(cuts[model_name], event_parameters, cut_name)\n",
    "        axs[i].hist((reconstructions[model_name][reconstructions_cut] - event_parameters['energy'][energy_cut]), label=model_description, **hist_args)\n",
    "    axs[i].set_title(f'Energy Resolution ({cut_name})', **LABEL_PARAMS)\n",
    "    axs[i].set_xlabel(r'$\\log_{10}(E_{\\mathrm{reco}}/\\mathrm{GeV}) - \\log_{10}(E_{\\mathrm{true}}/\\mathrm{GeV})$', **LABEL_PARAMS)\n",
    "    axs[i].set_ylabel('Counts', **LABEL_PARAMS)\n",
    "    axs[i].legend()\n",
    "    axs[i].axvline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot zoomed and unlogged energy resolution\n",
    "\n",
    "hist_args = {'range':(-1,1), 'bins':121, 'density':True, 'histtype':'step', 'log':False, 'linewidth':4}\n",
    "fig, axs = plt.subplots(figsize=(13*ncols, 8), ncols=ncols)\n",
    "\n",
    "for i, cut_name in enumerate(cut_names):\n",
    "    for model_name, model_description in MODEL_NAMES_AND_NUCLEI.items():\n",
    "        reconstructions_cut, energy_cut = get_cuts(cuts[model_name], event_parameters, cut_name)\n",
    "        axs[i].hist((reconstructions[model_name][reconstructions_cut] - event_parameters['energy'][energy_cut]), label=model_description, **hist_args)\n",
    "    axs[i].set_title(f'Energy Resolution ({cut_name})', **LABEL_PARAMS)\n",
    "    axs[i].set_xlabel(r'$\\log_{10}(E_{\\mathrm{reco}}/\\mathrm{GeV}) - \\log_{10}(E_{\\mathrm{true}}/\\mathrm{GeV})$', **LABEL_PARAMS)\n",
    "    axs[i].set_ylabel('Counts', **LABEL_PARAMS)\n",
    "    axs[i].legend()\n",
    "    axs[i].axvline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in MODEL_NAMES_AND_NUCLEI.keys():\n",
    "    for cut_name in cut_names:\n",
    "        reconstructions_cut, energy_cut = get_cuts(cuts[model_name], event_parameters, cut_name)\n",
    "        median, err_min, err_max = np.percentile(reconstructions[model_name][reconstructions_cut] - event_parameters['energy'][energy_cut], (50,16,84))\n",
    "        print(f'Energy resolution for {model_name} ({cut_name}): {median:.3f} +{err_max:.3f} {err_min:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-Dimensional Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide = 'ignore')\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(13*ncols, 10*nrows), ncols=ncols, nrows=nrows,\n",
    "                        sharex=True, sharey=True)\n",
    "\n",
    "for i, model_name in enumerate(MODEL_NAMES_AND_NUCLEI.keys()):\n",
    "    for j, cut_name in enumerate(cut_names):\n",
    "        \n",
    "        ax = axs[i, j] if nrows > 1 else axs[j]\n",
    "        ax.tick_params(axis='both', direction='out', labelsize=14)\n",
    "        reconstructions_cut, energy_cut = get_cuts(cuts[model_name], event_parameters, cut_name)\n",
    "        \n",
    "        h, xedges, yedges = np.histogram2d(reconstructions[model_name][reconstructions_cut], event_parameters['energy'][energy_cut], bins=(ebins, ebins), density=False, weights=None)\n",
    "        \n",
    "        # Normalize\n",
    "        ntot = np.sum(h, axis=0).astype(float)\n",
    "        ntot[ntot==0] = 1.\n",
    "        h /= ntot\n",
    "        \n",
    "        # Create contours\n",
    "        contour_values = [0.025, 0.16, 0.84, 0.975]\n",
    "        contour_list = [[] for _ in contour_values]\n",
    "        for c, col in enumerate(h.transpose()):\n",
    "            ccol = col.cumsum()\n",
    "            for l, val in zip(contour_list, contour_values):\n",
    "                try: l += [np.where(ccol > val)[0][0]]\n",
    "                except IndexError:\n",
    "                    l += [0]\n",
    "        for l in contour_list:\n",
    "            l.insert(0, l[0])\n",
    "            if i >= len(contour_list) / 2:\n",
    "                l = [j+1 for j in l]\n",
    "            ax.step(ebins, ebins[l], color='red', linestyle='--')\n",
    "        \n",
    "        ax.plot(evalues, evalues, 'k', ls=':')\n",
    "        \n",
    "        # Plot on a log scale\n",
    "        extent = [yedges[0], yedges[-1], xedges[0], xedges[-1]]\n",
    "        im = ax.imshow(np.log10(h), extent=extent, origin='lower', interpolation='none', vmin=-3.5, vmax=-0.5)\n",
    "        ax.set_title(f'{model_name} {cut_name}', **LABEL_PARAMS)\n",
    "        ax.set_xlabel(r'$\\log_{10}(E_{\\mathrm{true}}/\\mathrm{GeV})$', **LABEL_PARAMS)\n",
    "        ax.set_ylabel(r'$\\log_{10}(E_{\\mathrm{reco}}/\\mathrm{GeV})$', **LABEL_PARAMS)\n",
    "        #ax.tick_params(labelsize=24)\n",
    "        ax.set_yticks(np.linspace(5.5, 8, num=6))\n",
    "        #im.ax.tick_params(labelsize=20) \n",
    "        cbar = fig.colorbar(im, ax=ax)\n",
    "        cbar.ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Resolution as a Function of Zenith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coszbins = np.linspace(0.4,1,20)\n",
    "coszvalues = (coszbins[1:]+coszbins[:-1])/2\n",
    "kwargs = {'fmt':'.',\n",
    "          'markersize':40,\n",
    "          'elinewidth':2,\n",
    "          'capsize':10,\n",
    "          'capthick':2}\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(26, 10), ncols=1)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "for k, model_name in enumerate(MODEL_NAMES_AND_NUCLEI.keys()):\n",
    "    \n",
    "    theta = np.pi - event_parameters['laputop_dir'].transpose()[0].astype('float64')[cuts[model_name]]\n",
    "\n",
    "    array_info = np.zeros(shape=(len(coszvalues), 3))\n",
    "    reconstructions_cut, energy_cut = get_cuts(cuts[model_name], event_parameters, 'No Cut')\n",
    "    binned_zenith = np.digitize(np.cos(theta)[reconstructions_cut], coszbins) - 1\n",
    "    for j in range(len(coszvalues)):\n",
    "        coszcut = (binned_zenith == j)\n",
    "        temp_events = reconstructions[model_name][reconstructions_cut][coszcut]\n",
    "        if len(temp_events) != 0:\n",
    "            array_info[j] = np.percentile(temp_events - event_parameters['energy'][energy_cut][coszcut], (50, 16, 84))\n",
    "\n",
    "    median, err_min, err_max = np.transpose(array_info)\n",
    "    axs.errorbar(coszvalues, median, yerr=(median-err_min, err_max-median), label=model_name, **kwargs)\n",
    "    \n",
    "    axs.axhline(color='k', ls='--')\n",
    "    axs.set_title('Energy Resolution v. Zenith (No Cut)', **LABEL_PARAMS)\n",
    "    axs.set_xlabel(r'$\\cos(\\theta)$', loc='right', **LABEL_PARAMS)\n",
    "    axs.set_ylabel(r'$\\log_{10}(E_{\\mathrm{reco}}/\\mathrm{GeV}) - \\log_{10}(E_{\\mathrm{true}}/\\mathrm{GeV})$', **LABEL_PARAMS)\n",
    "    axs.set_ylim(-0.25, 0.25)\n",
    "    #axs.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
